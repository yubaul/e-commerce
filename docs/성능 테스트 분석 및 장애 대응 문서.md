# 부하 테스트 성능 지표 분석 및 장애 대응 문서

## 1. 테스트 개요

이번 단계에서는 이전에 작성한 K6 스크립트를 활용하여 **주문/결제 API**를
대상으로 부하 테스트를 진행하였습니다.\
시스템은 오케스트레이션 기반 SAGA + Outbox 패턴 + 분산락(`@CommonLock`)
구조이며, Kafka 브로커는 단일 노드(파티션 3개) 환경이었습니다.

------------------------------------------------------------------------

## 2. 테스트 환경

-   **도구**: k6 (ramping-arrival-rate)
-   **부하 조건**:
    -   시작 10 RPS → 40 → 60 → 80 (각 30초 유지)
    -   Virtual User: 50 \~ 200
-   **데이터 준비**:
    -   사용자 200명 (ID: 1300\~1499)
    -   아이템 100개 (핫 아이템 + 일반 아이템 혼합)
    -   계좌 잔액 충분히 충전

------------------------------------------------------------------------

## 3. 성능 지표 (주요 결과)

-   **총 요청 수**: 4,138건
-   **에러율**: 0% (모든 요청 2xx 처리)
-   **평균 응답 시간**: 988ms
-   **p95**: 2.21s
-   **p99**: 3.95s
-   **최대 응답 시간**: 5.95s
-   **드랍된 요청**: 212건 (전체의 약 5%)

------------------------------------------------------------------------

## 4. 분석

1.  **에러율 측면**\
    모든 요청이 정상적으로 처리되었으며 데이터 정합성 문제는 발생하지
    않았습니다.\
    분산락 적용으로 중복 처리나 재고 차감 오류는 방지되었습니다.

2.  **지연 시간(Tail Latency)**\
    평균 응답 시간은 비교적 안정적이었으나, p95\~p99 구간에서
    SLA(1.2s)를 크게 초과하였습니다.\
    이는 Outbox 테이블 경합과 Kafka 브로커의 단일 노드 구성으로 인한
    처리 지연이 주요 원인으로 분석됩니다.

3.  **Outbox 처리 병목**\
    Outbox 상태 전환이 일부 PUBLISHED 상태에서 멈추는 현상이
    발생하였습니다.\
    이는 Consumer 트랜잭션 동기화 문제 및 락 경합이 겹치면서 발생하는
    것으로 보입니다.

------------------------------------------------------------------------

## 5. 개선 방안

1.  **Kafka 확장**
    -   단일 브로커 → 멀티 브로커/멀티 파티션 구성으로 확장 필요
    -   Acks=all 및 idempotence 유지하되, 적절한 batch.size 및 linger.ms
        조정
2.  **Outbox 최적화**
    -   Consumer 쪽 트랜잭션 경계 재검토 (@Transactional 전파 수준 조정)
    -   Outbox 상태 업데이트 전용 쓰레드 풀 운영 고려
3.  **락 경합 완화**
    -   Hot Item 트래픽 분산 (더 많은 아이템 분포 사용)
    -   락 대기 시간/임대 시간 파라미터 조정
4.  **부하 기준 재설정**
    -   현재 환경에서는 30\~40 RPS 수준이 안정 구간으로 판단됨
    -   SLA 목표에 맞추어 운영 기준 조정 필요

------------------------------------------------------------------------

## 6. 가상 장애 대응 시나리오

1.  **Kafka 브로커 장애**
    -   장애 시 Outbox 테이블에서 재처리 → DLQ 이동 후 복구
    -   멀티 브로커 환경에서 리더 선출로 자동 복구
2.  **DB 락 경합 폭증**
    -   재고/계좌 차감 시 지연 발생 → 임시적으로 큐 기반 비동기 처리
        전환
    -   관리자 대시보드에서 모니터링 후 트래픽 분산
3.  **Outbox 상태 누락**
    -   모니터링 배치 잡으로 PUBLISHED 상태 이벤트 재시도
    -   Kafka consumer 재기동 시 자동 보정 확인

------------------------------------------------------------------------

## 7. 결론

이번 테스트를 통해 **현재 단일 노드 Kafka + Outbox + 분산락 구조의
한계**가 명확히 드러났습니다.\
시스템이 안정적으로 처리 가능한 수준은 약 30\~40 RPS이며, 이를 초과할
경우 지연 시간이 급격히 증가하고 Outbox 병목이 발생하였습니다.\
향후 운영 환경에서는 **Kafka 클러스터링, Outbox 최적화, 락 파라미터
조정** 등을 통해 확장성과 안정성을 확보해야 할 것입니다.
