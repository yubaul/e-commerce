# 선착순 쿠폰 발급 Outbox Pattern 기반 Kafka 이벤트 처리 설계 문서

## 1. 개요
**선착순 쿠폰 발급**을 고부하 상황에서도 안정적으로 처리하기 위해  
**Redis Queue Guard + Outbox Pattern + Kafka** 기반의 이벤트 드리븐 아키텍처를 적용하였습니다.

구체적으로는 다음과 같습니다.
- **Redis**: 쿠폰 발급 요청 시 중복 및 수량 제한 보장
- **Outbox 패턴**: DB 트랜잭션과 이벤트 발행의 원자성 확보
- **Kafka Producer/Consumer**: 비동기 처리 및 확장성 보장
- **ErrorHandler + DLQ**: 메시지 처리 실패 시 재시도 및 Dead Letter Queue 보장

---

## 2. Kafka 구성

### 토픽
- **coupon-issue**: 쿠폰 발급 이벤트
- **coupon-issue.DLQ**: 소비 실패 시 Dead Letter Queue

### Producer 설정
- `acks=all`, `enable.idempotence=true` → 중복 방지 및 신뢰성 확보
- `JsonSerializer` 기반 직렬화
- OutboxEvent payload(JSON 문자열) 그대로 Kafka에 push

### Consumer 설정
- `@KafkaListener` 기반 멀티 파티션 병렬 소비 (concurrency=3)
- `AckMode.MANUAL` → 처리 성공 시 수동 오프셋 커밋
- `DefaultErrorHandler` + `DeadLetterPublishingRecoverer`
    - 최대 3회 재시도
    - 실패 시 `.DLQ` 토픽으로 이동

---

## 3. 에러 핸들링 & DLQ 전략

1. **일시적 오류** (네트워크 지연, DB Deadlock 등)
    - `DefaultErrorHandler`에서 최대 3회 재시도
    - 성공 시 정상 커밋

2. **영구적 오류** (역직렬화 실패, 유효성 위반 등)
    - 재시도 후에도 실패 시 `.DLQ` 토픽으로 이동
    - 운영자가 DLQ 모니터링하여 후속 조치

---

## 4. Outbox Event Schema

```sql
CREATE TABLE outbox_event (
  id             BIGINT PRIMARY KEY AUTO_INCREMENT,
  topic          VARCHAR(30) NOT NULL,
  aggregate_id   VARCHAR(50) NOT NULL,
  type           VARCHAR(50) NOT NULL,
  payload        MEDIUMTEXT NOT NULL,
  headers        TEXT NULL,
  occurred_at    TIMESTAMP(3) NOT NULL DEFAULT CURRENT_TIMESTAMP(3),
  status         VARCHAR(20) NOT NULL DEFAULT 'PENDING',
  retry_count    INT NOT NULL DEFAULT 0,
  last_error     TEXT NULL,
  published_at   TIMESTAMP(3) NULL,
  CONSTRAINT uk_outbox_topic_agg UNIQUE (topic, aggregate_id),
  INDEX idx_outbox_status_occurred (status, occurred_at),
  INDEX idx_outbox_topic_status (topic, status)
);
```

- 현재는 **`topic + aggregate_id`** 조합으로 Unique Key가 설정되어 있습니다.
- 따라서 한 `(쿠폰ID, 유저ID)` 조합당 이벤트는 1개만 기록할 수 있습니다.

---

## 5. 현재 한계점 및 개선 방향

### 한계점
- `aggregateId = couponId-userId` 방식으로 설정되어 있습니다.
- 그 결과, **한 유저의 특정 쿠폰 발급 이벤트는 단 1개만 Outbox에 기록**할 수 있습니다.
- 발급 요청/재시도/실패/성공 같은 다중 이벤트를 모두 Outbox에 기록하기 어렵습니다.
- 확장성 측면에서 제약이 존재합니다.

### 개선 방향
1. **eventId(UUID) 도입**
    - OutboxEvent에 `event_id` 칼럼을 추가하여 PK/UK 보장
    - `aggregateId`는 단순히 비즈니스 엔티티 식별자(couponId 등)만 저장
    - 이벤트 유일성은 `eventId`가 담당

   ```sql
   ALTER TABLE outbox_event DROP INDEX uk_outbox_topic_agg;
   ALTER TABLE outbox_event ADD COLUMN event_id CHAR(36) NOT NULL UNIQUE;
   ALTER TABLE outbox_event ADD INDEX idx_topic_agg (topic, aggregate_id);
   ```

   ```java
   public OutboxEvent toOutboxEventEntity() {
       return OutboxEvent.builder()
           .eventId(UUID.randomUUID().toString())
           .topic(KafkaConstant.COUPON_ISSUE)
           .aggregateId(couponId.toString())
           .type(OutboxEventConstant.TYPE_COUPON_ISSUED)
           .status(OutboxEvent.OutboxEventStatus.PENDING)
           .payload(JsonMapper.toJson(this))
           .occurredAt(LocalDateTime.now())
           .build();
   }
   ```

2. **OutboxEventReader 개선**
    - 기존 `findByTopicAndAggregateId()` 방식 대신
    - `findByEventId()`로 조회하도록 개선

3. **추가 이벤트 기록 가능**
    - "발급 요청", "발급 성공", "발급 실패" 등 다양한 이벤트를 Outbox에 누적 관리 가능

---

## 6. 결론

본 설계는 **Redis Guard + Outbox Pattern + Kafka** 조합을 통해  
대규모 트래픽 상황에서도 **쿠폰 발급의 정합성과 안정성**을 보장합니다.

다만, OutboxEvent의 **aggregateId 설계 제약**으로 인해 현재는 이벤트 다변화가 제한됩니다.  
향후 `eventId` 중심으로 재설계한다면 Outbox 패턴의 본래 목적(모든 이벤트 로그 보존 + 유연한 소비)을  
온전히 달성할 수 있을 것입니다.
