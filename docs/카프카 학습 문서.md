# Kafka 기초 학습 문서

## 1. Kafka 기본 개념

Apache Kafka는 **분산 스트리밍 플랫폼**으로, 대규모 실시간 데이터 파이프라인과 스트리밍 애플리케이션을 구축하는 데 사용됩니다.  
메시지 브로커이자 로그 저장소 역할을 수행하며, **확장성·내결함성·고성능**을 특징으로 합니다.

### 주요 구성 요소

- **Producer (프로듀서)**
    - 메시지를 생성하고 Kafka **Topic**에 전송하는 주체입니다.
    - 메시지는 Key-Value 구조로 전송 가능하며, Key가 같으면 동일 파티션으로 전달되어 **순서 보장**이 가능합니다.

- **Topic (토픽)**
    - 메시지를 구분하는 단위(카테고리)입니다.
    - 각 토픽은 **Partition**으로 나누어져 있으며, 병렬 처리와 확장성을 보장합니다.

- **Partition (파티션)**
    - 토픽의 하위 단위입니다.
    - 각 파티션은 **Append-Only 로그** 구조를 가지며, 메시지는 오프셋(offset)으로 식별됩니다.
    - 파티션 개수와 키 전략에 따라 **부하 분산** 및 **순서 보장**이 결정됩니다.

- **Consumer (컨슈머)**
    - 특정 토픽의 메시지를 구독하여 처리하는 주체입니다.
    - 컨슈머들은 **Consumer Group** 단위로 동작하며, 동일 그룹 내 컨슈머들은 파티션을 나누어 읽습니다.

- **Broker (브로커)**
    - Kafka 서버 프로세스입니다. 일반적으로 다수의 브로커를 클러스터로 묶어 운영합니다.
    - 메시지 저장·전송·파티션 분산을 담당합니다.

- **Controller (컨트롤러)**
    - 브로커 중 하나가 선출되어 클러스터 메타데이터를 관리합니다.
    - 파티션 리더 선출, 브로커 상태 관리 등을 담당합니다.

- **Coordinator (코디네이터)**
    - 컨슈머 그룹을 관리하는 역할을 합니다.
    - 각 그룹은 그룹 코디네이터 브로커를 통해 **리밸런싱**과 오프셋 커밋을 수행합니다.

- **Leader / Follower (리더 / 팔로워)**
    - 각 파티션은 리더와 팔로워로 복제됩니다.
    - **리더**: 읽기·쓰기 요청을 처리합니다.
    - **팔로워**: 리더의 데이터를 복제하여 장애를 대비합니다.

- **Rebalancing (리밸런싱)**
    - 컨슈머 그룹의 컨슈머 수나 파티션 수가 변할 때 파티션을 재분배하는 과정입니다.
    - 잠시동안 컨슈머가 메시지를 소비하지 못하는 공백이 발생할 수 있어, **최소화 전략**이 필요합니다.

---

## 2. Kafka 동작 흐름

1. Producer가 메시지를 Topic에 전송합니다.
2. Topic은 여러 Partition으로 나뉘어 메시지를 저장합니다.
3. Partition마다 Leader Replica가 메시지를 처리하고, Follower Replica가 이를 복제합니다.
4. Consumer Group의 Consumer가 Partition에서 메시지를 읽습니다.
5. Consumer는 읽은 위치를 Offset으로 관리합니다.
6. Coordinator가 그룹의 상태를 관리하며 필요 시 Rebalancing을 수행합니다.

---

## 3. Kafka 로컬 설치 및 기본 명령어

### 설치
```bash
# Zookeeper & Kafka 실행 (Kafka 3.x부터는 KRaft 모드 사용 가능)
bin/zookeeper-server-start.sh config/zookeeper.properties
bin/kafka-server-start.sh config/server.properties
```

### 토픽 생성
```bash
bin/kafka-topics.sh --create --topic order-payment --bootstrap-server localhost:9092 --partitions 3 --replication-factor 1
```

### 프로듀서 실행
```bash
bin/kafka-console-producer.sh --topic order-payment --bootstrap-server localhost:9092
```

### 컨슈머 실행
```bash
bin/kafka-console-consumer.sh --topic order-payment --from-beginning --bootstrap-server localhost:9092
```

---

## 4. Spring Boot에서 Kafka 활용

### 의존성 추가
```gradle
implementation("org.springframework.kafka:spring-kafka")
```

### Producer 설정
```java
@Configuration
public class KafkaProducerConfig {
    @Bean
    public ProducerFactory<String, Object> producerFactory() {
        Map<String, Object> config = new HashMap<>();
        config.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, "localhost:9092");
        config.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class);
        config.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, JsonSerializer.class);
        return new DefaultKafkaProducerFactory<>(config);
    }

    @Bean
    public KafkaTemplate<String, Object> kafkaTemplate() {
        return new KafkaTemplate<>(producerFactory());
    }
}
```

### Consumer 설정
```java
@Configuration
@EnableKafka
public class KafkaConsumerConfig {
    @Bean
    public ConsumerFactory<String, Object> consumerFactory() {
        Map<String, Object> config = new HashMap<>();
        config.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, "localhost:9092");
        config.put(ConsumerConfig.GROUP_ID_CONFIG, "order-payment-group");
        config.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class);
        config.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, JsonDeserializer.class);
        config.put(JsonDeserializer.TRUSTED_PACKAGES, "*");
        return new DefaultKafkaConsumerFactory<>(config);
    }

    @Bean
    public ConcurrentKafkaListenerContainerFactory<String, Object> kafkaListenerContainerFactory() {
        var factory = new ConcurrentKafkaListenerContainerFactory<String, Object>();
        factory.setConsumerFactory(consumerFactory());
        return factory;
    }
}
```

### Producer 사용 예시
```java
@Component
@RequiredArgsConstructor
public class OrderEventProducer {
    private final KafkaTemplate<String, Object> kafkaTemplate;

    public void sendOrderCompletedEvent(OrderCompleted event) {
        kafkaTemplate.send("order-payment", event.getId().toString(), event);
    }
}
```

### Consumer 사용 예시
```java
@Slf4j
@Component
public class OrderEventConsumer {
    @KafkaListener(topics = "order-payment", groupId = "order-payment-group")
    public void consume(OrderCompleted event) {
        log.info("Consumed event: {}", event);
    }
}
```

---

## 5. 학습 포인트 & 심화 개념

- **토픽 파티셔닝 전략**
    - `key=null` → 라운드 로빈 분배
    - `key=고정값` → 특정 파티션으로 매핑 (순서 보장)

- **Exactly-Once 보장**
    - Producer Idempotence + Transactional Producer 조합 필요합니다.
    - Kafka Streams, Flink 같은 프레임워크에서 주로 활용됩니다.

- **Rebalancing 최소화 전략**
    - **Static Membership**: Consumer Group 재시작 시 동일 멤버 ID로 재참여.
    - **Incremental Rebalancing**: 전체 그룹 대신 일부만 재조정.

- **실무 고려사항**
    - DLQ(Dead Letter Queue) 설계 및 운영
    - Retry & Backoff 정책 수립
    - Outbox 패턴 및 CDC(Debezium) 결합
    - **수동 커밋(AckMode.MANUAL)**을 통한 메시지 처리 후 안전한 오프셋 커밋
    - 모니터링: Kafka Lag Exporter, Prometheus, Grafana 활용

---

## 6. 정리

Kafka는 단순한 메시지 큐가 아니라 **분산 로그 기반 스트리밍 플랫폼**입니다.  
Producer/Consumer, Topic/Partition, Broker/Controller/Coordinator 개념을 명확히 이해하는 것이 기본입니다.  
Spring Boot에서는 `KafkaTemplate`과 `@KafkaListener`를 통해 손쉽게 프로듀서·컨슈머를 구현할 수 있으며,  
실무에서는 **Outbox 패턴, 수동 커밋, DLQ 전략**을 결합하여 **신뢰성 있는 메시징 아키텍처**를 구현하는 것이 중요합니다.
